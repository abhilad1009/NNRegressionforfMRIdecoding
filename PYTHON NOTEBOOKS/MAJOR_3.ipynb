{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAJOR_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqyblAexfN5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "d36da3f0-366b-42d1-adbb-f7978671ecb0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "import pathlib\n",
        "\n",
        "import os\n",
        "\n",
        "print(os.getcwd())\n",
        "%cd ..\n",
        "%cd gdrive\n",
        "%cd My Drive\n",
        "%cd MAJOR PROJECT\n",
        "#data_root = pathlib.Path(\"/gdrive/My Drive/MAJOR PROJECT\")\n",
        "\n",
        "#%cd ./gdrive/My Drive/MAJOR PROJECT\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/content\n",
            "/\n",
            "/gdrive\n",
            "/gdrive/My Drive\n",
            "/gdrive/My Drive/MAJOR PROJECT\n",
            "/gdrive/My Drive/MAJOR PROJECT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K1fxw8UtCOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HouCWWfYfQvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -U tensorboard\n",
        "# !pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBX4ITazHEkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.preprocessing\n",
        "from sklearn import preprocessing\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdxmF8V0H3pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 500\n",
        "BATCH_SIZE = 1\n",
        "SHAPE = 128\n",
        "\n",
        "def load(image_file):\n",
        "  image = tf.io.read_file(image_file)\n",
        "  image = tf.image.decode_jpeg(image)\n",
        "\n",
        "  input_image = tf.cast(image, tf.float32)\n",
        "  \n",
        "  return input_image\n",
        "\n",
        "def resize(input_image, height, width):\n",
        "  input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  \n",
        "\n",
        "  return input_image\n",
        "\n",
        "def normalize(input_image):\n",
        "  input_image = (input_image / 127.5) - 1\n",
        "  \n",
        "\n",
        "  return input_image\n",
        "\n",
        "@tf.function()\n",
        "def random_jitter(input_image):\n",
        "  # resizing to 286 x 286 x 3\n",
        "  input_image = resize(input_image, SHAPE, SHAPE)\n",
        "\n",
        "  # randomly cropping to 256 x 256 x 3\n",
        "\n",
        "\n",
        "  return input_image\n",
        "\n",
        "def load_image_train(image_file):\n",
        "  input_image= load(image_file)\n",
        "  input_image= random_jitter(input_image)\n",
        "  input_image= normalize(input_image)\n",
        "\n",
        "  return input_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDrNgQYjGZDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "trainimg = tf.data.Dataset.list_files(os.getcwd()+'/TRAINS/*.*',shuffle=False)\n",
        "\n",
        "randomimg = tf.data.Dataset.list_files(os.getcwd()+'/RANDOM/VALID/*.png',shuffle=False)\n",
        "\n",
        "testimg = tf.data.Dataset.list_files(os.getcwd()+'/img_test/*.*',shuffle=False)\n",
        "\n",
        "\n",
        "trainimg = trainimg.map(load_image_train,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "randomimg = randomimg.map(load_image_train,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "testimg = testimg.map(load_image_train,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "random = randomimg.batch(128)\n",
        "# train = random.batch(128)\n",
        "# train_dataset = tf.data.Dataset.zip((mri,trainimg))\n",
        "train = trainimg.batch(1)\n",
        "# print(train)\n",
        "# train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "# train_dataset = train_dataset.batch(1)\n",
        "# print(train_dataset)\n",
        "\n",
        "test = testimg.batch(1)\n",
        "# print(testimg)\n",
        "# test_dataset =tf.data.Dataset.zip((mri_test,testimg))\n",
        "# test_dataset = test_dataset.shuffle(BUFFER_SIZE)\n",
        "# test_dataset = test_dataset.batch(1)\n",
        "# print(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNeBBLJPhpxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IM=inception.predict(train)\n",
        "IMT=inception.predict(test)\n",
        "# feat = tf.data.Dataset.from_tensor_slices(IMT)\n",
        "# test_dataset =tf.data.Dataset.zip((feat,testimg))\n",
        "# test_dataset = test_dataset.shuffle(BUFFER_SIZE)\n",
        "# test_dataset = test_dataset.batch(4)\n",
        "feat= inception.predict(random)\n",
        "# print(len(IM))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYN_qRxim7e0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "\n",
        "# h5f = h5py.File('valid4096_data.h5', 'w')\n",
        "# h5f.create_dataset('train', data=feat)\n",
        "# h5f.close()\n",
        "# h5f = h5py.File('train4096_data.h5', 'w')\n",
        "# h5f.create_dataset('train', data=IM)\n",
        "# h5f.close()\n",
        "# h5f = h5py.File('test4096_data.h5', 'w')\n",
        "# h5f.create_dataset('test', data=IMT)\n",
        "# h5f.close()\n",
        "# h5f = h5py.File('validvgg_data.h5','r')\n",
        "# random = h5f['train'][:]\n",
        "# h5f.close()\n",
        "# h5f = h5py.File('train4096_data.h5','r')\n",
        "# IM = h5f['train'][:]\n",
        "# h5f.close()\n",
        "# h5f = h5py.File('testvgg_data.h5','r')\n",
        "# IMT = h5f['test'][:]\n",
        "# h5f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4j_LfcwAWGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random=tf.data.Dataset.from_tensor_slices(random)\n",
        "feat_ds = tf.data.Dataset.zip((random,randomimg))\n",
        "feat_ds = feat_ds.shuffle(BUFFER_SIZE)\n",
        "feat_ds = feat_ds.batch(64)\n",
        "print(feat_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYSdax-3h7rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_feat= tf.data.Dataset.from_tensor_slices(IM)\n",
        "train_data = tf.data.Dataset.zip((train_feat,trainimg))\n",
        "train_data = train_data.shuffle(BUFFER_SIZE)\n",
        "train_data = train_data.batch(16)\n",
        "print(train_data)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEtJvxoBBTqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random=None\n",
        "feat=None\n",
        "IM=None\n",
        "IMT=None\n",
        "randomimg=None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIkaoAs64S51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator():\n",
        "    model=tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.Input(shape=(8192)))\n",
        "    model.add(layers.Dense(8192))\n",
        "\n",
        "    model.add(layers.Reshape((4, 4, 512)))\n",
        "    assert model.output_shape == (None, 4, 4, 512) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 8, 8, 512)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 16, 16, 512)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 32, 32, 256)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 64, 64, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 128, 128, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3, (3, 3), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 128, 128, 3)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKJN7ztBb-vA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = Generator()\n",
        "# tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n",
        "# generator.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKOh4SuGoowy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Discriminator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(16, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[128, 128, 3])) # 64*64*16\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')) # 32*32*64\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    # model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')) # 16*16*128\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same')) # 8*8*256\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same')) # 8*8*256\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_aLYYE53igL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = Discriminator()\n",
        "# discriminator =tf.keras.models.load_model('DISCRIMINATOR')\n",
        "# tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKMD2vNwbRR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LAMBDA = 1000\n",
        "\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  # mean absolute error\n",
        "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "\n",
        "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "  return total_gen_loss, gan_loss, l1_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRU4kYP7aS2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI68bAl63642",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_disc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d636xrqEbMR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D34iExXbYT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints8192'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpM9AuoncnDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_images(model, test_input, tar):\n",
        "  prediction = model(test_input, training=True)\n",
        "  plt.figure(figsize=(5,5))\n",
        "\n",
        "  display_list = [ tar[0], prediction[0]]\n",
        "  title = ['Ground Truth', 'Predicted Image']\n",
        "\n",
        "  for i in range(2):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.title(title[i])\n",
        "    # getting the pixel values between [0, 1] to plot it.\n",
        "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR-EYoLE8B-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step_1(input_image,target, epoch):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape :\n",
        "\n",
        "    gen_output = generator(input_image, training=True)\n",
        "\n",
        "    disc_real_output = discriminator(target, training=True)\n",
        "    disc_generated_output = discriminator(gen_output, training=True)\n",
        "\n",
        "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "\n",
        "  generator_gradients = gen_tape.gradient(gen_total_loss,\n",
        "                                          generator.trainable_variables)\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                               discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                          generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                              discriminator.trainable_variables))\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3n7vjDqbiTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(feat_ds,train_ds,test_ds, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "\n",
        "    # Train\n",
        "    print(epoch)\n",
        "\n",
        "    for n, (input_image,target) in feat_ds.enumerate():\n",
        "      print('.', end='')\n",
        "      if (n+1) % 100 == 0:\n",
        "        print()\n",
        "      train_step_1(input_image,target, epoch)\n",
        "    print()\n",
        "\n",
        "\n",
        "    for (example_input,example_target) in test_ds.take(1):\n",
        "        generate_images(generator, example_input, example_target)\n",
        "    print(\"TEST Epoch: \", epoch)\n",
        "\n",
        "    # saving (checkpoint) the model every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
        "                                                        time.time()-start))\n",
        "  # checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr_ELJU26wfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbU_ZS0Mbiy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "fit(feat_ds,feat_ds,test_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEqMWBaIjOjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator.save('GENERATOR8192')\n",
        "# discriminator.save('DISCRIMINATOR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3g3wJlnoMfP",
        "colab_type": "text"
      },
      "source": [
        "#Neural Network Regression for fMRI decoding\n",
        "\n",
        "---\n",
        "\n",
        "Code repository for [Neural Network Regression for fMRI decoding]()\n",
        "\n",
        "##Requirements\n",
        "---\n",
        "\n",
        "\n",
        "*   Python 3.x\n",
        "*   Tensorflow\n",
        "*   Numpy\n",
        "*   Matplotlib\n",
        "*   H5py\n",
        "*   Scipy\n",
        "*   Sklearn\n",
        "*   Pandas\n",
        "\n",
        "##Data\n",
        "---\n",
        "The required data can be downloaded from the following links:\n",
        "\n",
        "* [ImageNet validation set]()\n",
        "\n",
        "* [fMRI data]()\n",
        "\n",
        "##Setting up files\n",
        "---\n",
        "The data files should be places in structure given below:\n",
        "\n",
        "    Project Folder\n",
        "        |____ data\n",
        "                |____fmri\n",
        "                |     |____subject1.mat\n",
        "                |     |____imageID_training.csv\n",
        "                |     |____imageID_test.csv\n",
        "                |\n",
        "                |____TRAIN_IMG (training images corresponding to fmri)\n",
        "                |\n",
        "                |____TEST_IMG  (testing images corresponding to fmri)\n",
        "                |\n",
        "                |____GAN_TRAIN (validation set of imagenet)\n",
        "\n",
        "\n",
        "\n",
        "##Usage\n",
        "---\n",
        "* Install all the mentioned requirements.\n",
        "\n",
        "* Download necessary data from the given links and place them in given folder structure.\n",
        "\n",
        "###Extracting VGG19 features\n",
        "\n",
        "* Run the [vgg19_features.py]() file to extract necessary features. The extracted features are stored in [data]() folder with .h5 extension.\n",
        "\n",
        "###Training image generating model\n",
        "\n",
        "* Run [gan_model.py]() for training image generating model. After the script completes, the saved model can be found in saved_models folder.\n",
        "\n",
        "* This can also be done in step-by-step manner by running the [gan_model.ipynb]() notebook. This is highy recommended for understanding and tinkering with the code.\n",
        "\n",
        "###Training neural network decoder\n",
        "\n",
        "* Runnig [decoder.py]() will train the decoder and show the images generated from test fmri data. The default values for decoder variables can be changes before running the script.\n",
        "\n",
        "* This can also be done in step-by-step manner by running the [decoder.ipynb]() notebook. This is highy recommended for understanding and tinkering with the code.\n",
        "\n",
        "###Results\n",
        "\n",
        "The images generated by decoding test fmri data can be found in results folder.\n",
        "\n",
        "\n"
      ]
    }
  ]
}